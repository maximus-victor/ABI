---
title: "Exercise05_noncodingRNA"
author: "Maximilian Harl, Leon Hafner, Leon Rauschning, David Wagemann"
date: "21.6.2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exercise 05 - noncoding RNA

This is where the exercise starts. You can also delete the chunks above in your final version.

```{r}
# some setups
set.seed(123)

# load libraries
library(SPONGE)
library(data.table)
library(doParallel)
library(foreach)
library(dplyr)

library(caret)

# parallelization
num.of.cores <- 8
cl <- makeCluster(num.of.cores) 
registerDoParallel(cl)
```

## a) Data acquisition and preparation 

```{r}
load("oldCohort.RData")
genexp <- tgct_oldCohort_gene_expression
meta <- tgct_oldCohort_metaData
mirna <- tgct_oldCohort_miRNA_expression

train_idx <- createDataPartition(
  y = meta$SUBTYPE,
  p = .5,
  list = FALSE
)

train_meta = meta[train_idx,]
test_meta = meta[-train_idx,]

genexp_train = genexp[, train_meta$sampleID]
genexp_test = genexp[, test_meta$sampleID]

```

## b) Sponge modules 

```{r}
ceRNA_interactions <- data.table::fread('testicular_germ_cell_tumor/testicular_germ_cell_tumor_networkInteractions_full.csv') 
network_centralities <- data.table::fread('testicular_germ_cell_tumor/testicular_germ_cell_tumor_networkAnalysis.csv')

colnames(ceRNA_interactions)[which(colnames(ceRNA_interactions) == 'GeneA')] <- 'geneA'
colnames(ceRNA_interactions)[which(colnames(ceRNA_interactions) == 'GeneB')] <- 'geneB'

# untested
filtered_network_centralities <- filter_ceRNA_network(
	sponge_effects = ceRNA_interactions,
	Node_Centrality = network_centralities,
	add_weighted_centrality=T,
	mscor.threshold = 0.01,
	padj.threshold = 0.1)

RNAs <- c("lncRNA")
RNAs.ofInterest <- ensembl.df %>% dplyr::filter(gene_biotype %in% RNAs) %>%
  dplyr::select(ensembl_gene_id)

central_gene_modules <- get_central_modules(central_nodes = RNAs.ofInterest$ensembl_gene_id,node_centrality = filtered_network_centralities$Node_Centrality, ceRNA_class = RNAs, centrality_measure = "Weighted_Degree", cutoff = 10)

Sponge.modules <- define_modules(network = filtered_network_centralities$Sponge.filtered,
	central.modules = central_gene_modules,
	remove.central = F,
	set.parallel = F)

Size.modules <- sapply(Sponge.modules, length)

```

## c) Module enrichment + Machine learning

```{r}
gc() # Call garbage collector to free some RAM
train.modules <- enrichment_modules(Expr.matrix = genexp_train, modules = Sponge.modules, bin.size = 10, min.size = 1, max.size = 2000, min.expr = 1, method = "OE", cores=1)

gc() # Call garbage collector to free some RAM
test.modules <-  enrichment_modules(Expr.matrix = genexp_test, modules = Sponge.modules, bin.size = 10, min.size = 1, max.size = 2000, min.expr = 1, method = "OE", cores=1)

gc() # Call garbage collector to free some RAM

common_modules = intersect(rownames(train.modules), rownames(test.modules))
train.modules = train.modules[common_modules, ]
test.modules = test.modules[common_modules, ]

trained.model = calibrate_model(Input = train.modules, modules_metadata = train_meta, label = "SUBTYPE", sampleIDs = "sampleID",Metric = "Exact_match", n_folds = 2, repetitions = 1)

```

```{r}

Input.test <- t(test.modules) %>% scale(center = T, scale = T)
Prediction.model <- predict(trained.model$Model, Input.test)

# We compute the confusion metrix [sic] on the test set
ConfusionMatrix_testing <- caret::confusionMatrix(as.factor(Prediction.model), as.factor(test_meta$SUBTYPE))
trained.model$ConfusionMatrix_testing<-ConfusionMatrix_testing

print(paste0('Sensitivity: ', ConfusionMatrix_testing$byClass[["Specificity"]])) #1.0000
print(paste0('Specificity: ', ConfusionMatrix_testing$byClass[["Sensitivity"]])) #1.0000
print(paste0('Balanced Accuracy: ', ConfusionMatrix_testing$byClass[["Balanced Accuracy"]])) #1.0000
```
## d) Visualisation and Interpretation

```{r}
plot_top_modules(trained_model=trained.model, k_modules_red = 2, k_modules = 4)
```
Der Plot zeigt die Modules, welche am meisten zum Ergebnis beitragen
```{r}
plot_density_scores(trained_model=trained.model,spongEffects = train.modules, meta_data = train_meta, label = "SUBTYPE", sampleIDs = "sampleID")
```
NonSeminoma folgt nicht einer Normalverteilung. Dies weiÃŸt darauf hin, dass es innerhalb der Klasse unterschiede gibt (zB. verschiedene Subtypen)
```{r}
plot_heatmaps(trained_model = trained.model,spongEffects = train.modules,
               meta_data = train_meta, label = "SUBTYPE", sampleIDs = "sampleID",Modules_to_Plot = 2,
              show.rownames = F, show.colnames = F)
```
Die Samples lassen sich gut in die Gruppen NonSeminoma und Seminoma clustern
```{r}
```
I really want these bonus points!

```{r}
#this is getting out of hand...
```

```{r}
#stop your backend parallelisation if registered
stopCluster(cl) 
```
